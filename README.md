# ğŸ§ª Mini-OpenAI Research Lab

A tiny self-optimizing ML lab built in PyTorch and powered by the OpenAI API.

This project runs automated experiments on synthetic function-approximation tasks (like fitting sine waves), lets a GPT model propose new hyperparameters, trains networks, logs results, and generates research-style reports and visualizations.

Think of it as a mini version of an internal research loop: **planner â†’ experiments â†’ analysis â†’ interpretability â†’ new directions**.

---

## âœ¨ Features

- **Experiment Planner Agent**
  - Reads past experiment logs
  - Uses the OpenAI API to propose new hyperparameter configs  
    (layers, activation, learning rate, scheduler, epochs, etc.)

- **Training Loop (`lab_loop.py`)**
  - Runs multiple â€œlab cyclesâ€
  - Each cycle:
    - Fetches new configs from the planner agent
    - Trains MLPs on synthetic tasks (e.g. `sin`, `sin_combo`)
    - Logs results to `logs/experiment_log.jsonl`
    - Auto-generates a **research report** summarizing trends

- **Task System**
  - Built-in tasks like:
    - `sin`
    - `sin_combo` (sin + cos mixture)
  - GPT-powered **dataset generator agent** can write new task definitions to  
    `tasks/generated_tasks.jsonl` as Python expressions, e.g.  
    `math.sin(x) + 0.3 * math.cos(2 * x) + 0.05 * x**3`.

- **Visualization (`visualize_results.py`)**
  - Reconstructs the best modelâ€™s architecture
  - Quickly retrains it to approximate the function again
  - Produces:
    - `plots/function_fit.png` â€“ true vs predicted curve
    - `plots/hidden_vs_loss.png` â€“ hidden size vs final loss
    - `plots/lr_vs_loss.png` â€“ learning rate vs final loss

- **Interpretability (`interpretability_agent.py`)**
  - Hooks into the first hidden layer
  - Plots hidden activations across input space:
    - `plots/hidden_activations.png`

- **Research Director Agent (`research_director_agent.py`)**
  - Reads the log history
  - Proposes higher-level research directions:
    - new function families
    - regularization strategies
    - optimizers and LR schedules
    - alternative architectures

- **Streamlit Dashboard (`dashboard_app.py`)**
  - Web UI for the lab:
    - View all experiments as a table
    - Filter by task
    - See best config + metrics
    - View function-fit + hyperparam trend plots
    - Regenerate plots and hidden activations from the browser

---

## ğŸ§± Project Structure

```text
pytorch_practice/
â”œâ”€â”€ lab_core.py                 # Core models, task generation, logging utilities
â”œâ”€â”€ experiment_planner_agent.py # GPT-based hyperparameter planner
â”œâ”€â”€ lab_loop.py                 # Runs multi-cycle lab experiments & reports
â”œâ”€â”€ visualize_results.py        # Function fit + hyperparameter trend plots
â”œâ”€â”€ interpretability_agent.py   # Hidden-unit activation visualization
â”œâ”€â”€ dataset_generator_agent.py  # GPT-based new task generator
â”œâ”€â”€ research_director_agent.py  # High-level research suggestions
â”œâ”€â”€ dashboard_app.py            # Streamlit dashboard
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ experiment_log.jsonl    # Experiment records (appended over time)
â””â”€â”€ tasks/
    â””â”€â”€ generated_tasks.jsonl   # GPT-generated task definitions
